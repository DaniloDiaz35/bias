{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIAS AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\estudiante\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\estudiante\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:70\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten, Conv1D, MaxPooling1D, Dropout, InputLayer \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32mc:\\Users\\estudiante\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32mc:\\Users\\estudiante\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:85\u001b[0m\n\u001b[0;32m     83\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     87\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     88\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\Users\\estudiante\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Dropout, InputLayer # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from bias_reception import ReceptionBias\n",
    "from bias_dsp import FilterBias, ProcessingBias\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import cwt, morlet\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'bias (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/estudiante/Documents/GitHub/bias/bias/bin/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class AIBias:\n",
    "    def __init__(self, n, fs, channels, commands):\n",
    "        self._n = n\n",
    "        self._fs = fs\n",
    "        self._number_of_channels = channels\n",
    "        self._model = self.build_model()\n",
    "        self._is_trained = False\n",
    "        self._pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "        self._scaler = StandardScaler()\n",
    "        self._commands = commands\n",
    "\n",
    "        # Create a dynamic label map based on the provided commands\n",
    "        self._label_map = {command: idx for idx, command in enumerate(commands)}\n",
    "        self._reverse_label_map = {idx: command for command, idx in self._label_map.items()}\n",
    "\n",
    "    # Define getter\n",
    "    def ai_is_trained(self):\n",
    "        return self._is_trained\n",
    "    \n",
    "    def collect_and_train(self, reception_instance, filter_instance, processing_instance, samples_per_command, real_data=True):\n",
    "        \"\"\"\n",
    "        Collects EEG data, extracts features, and trains the model.\n",
    "        \"\"\"\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for command in self._commands:\n",
    "            for _ in range(samples_per_command):\n",
    "                # Get real data or generate synthetic data\n",
    "                if real_data:\n",
    "                    signals = reception_instance.get_real_data(channels=self._number_of_channels, n=self._n)\n",
    "                else:\n",
    "                    signals = generate_synthetic_eeg(n_samples=self._n, n_channels=self._number_of_channels, fs=self._fs)\n",
    "                \n",
    "                filtered_data = filter_instance.filter_signals(signals)\n",
    "                _, eeg_signals = processing_instance.process_signals(filtered_data)\n",
    "\n",
    "                # Extract features and append to X\n",
    "                features = self.extract_features(eeg_signals)\n",
    "                X.append(features)\n",
    "                y.append(self._label_map[command])\n",
    "\n",
    "        # Convert X and y to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Convert y to one-hot encoding\n",
    "        lb = LabelBinarizer()\n",
    "        y = lb.fit_transform(y)\n",
    "\n",
    "        # Train the model with the collected data\n",
    "        self.train_model(X, y)\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            InputLayer(shape=(self._number_of_channels, 55)),  # Adjusted input shape to match the feature count\n",
    "            Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Dropout(0.5),\n",
    "            Flatten(),\n",
    "            Dense(100, activation='relu'),\n",
    "            Dense(50, activation='relu'),\n",
    "            Dense(6, activation='softmax')  # 6 output classes (forward, backward, etc.)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def extract_features(self, eeg_data):\n",
    "        features = []\n",
    "        for ch, signals in eeg_data.items():\n",
    "            channel_features = []\n",
    "            for band_name, sig in signals.items():\n",
    "                sig = np.array(sig)\n",
    "\n",
    "                # Statistical Features\n",
    "                mean = np.mean(sig)\n",
    "                variance = np.var(sig)\n",
    "                skewness = skew(sig)\n",
    "                kurt = kurtosis(sig)\n",
    "                energy = np.sum(sig ** 2)\n",
    "\n",
    "                # Frequency Domain Features (Power Spectral Density)\n",
    "                freqs, psd = welch(sig, fs=self._fs)  # Assuming fs = 500 Hz\n",
    "\n",
    "                # Band Power for specific frequency bands (e.g., alpha, beta, theta)\n",
    "                alpha_power = np.sum(psd[(freqs >= 8) & (freqs <= 13)])\n",
    "                beta_power = np.sum(psd[(freqs >= 13) & (freqs <= 30)])\n",
    "                theta_power = np.sum(psd[(freqs >= 4) & (freqs <= 8)])\n",
    "                delta_power = np.sum(psd[(freqs >= 0.5) & (freqs <= 4)])\n",
    "                gamma_power = np.sum(psd[(freqs >= 30) & (freqs <= 100)])\n",
    "\n",
    "                # Use scipy.signal.cwt instead of pywt\n",
    "                scales = np.arange(1, 31)\n",
    "                coeffs = cwt(sig, morlet, scales)\n",
    "                wavelet_energy = np.sum(coeffs ** 2)\n",
    "\n",
    "                # Append all features together\n",
    "                channel_features.extend([mean, variance, skewness, kurt, energy,\n",
    "                                 alpha_power, beta_power, theta_power, delta_power, gamma_power,\n",
    "                                 wavelet_energy])\n",
    "                \n",
    "            features.append(channel_features)\n",
    "\n",
    "        features = np.abs(np.array(features))\n",
    "        features = self._scaler.fit_transform(features)  # Normalize\n",
    "        # Perform PCA if needed, currently commented out\n",
    "        # features = self._pca.fit_transform(features)  # Dimensionality Reduction\n",
    "\n",
    "        # Adjust reshaping based on actual size\n",
    "        # Get the total number of features per channel\n",
    "        num_features_per_channel = features.shape[1]\n",
    "\n",
    "        # Reshape based on the number of samples, channels, and features\n",
    "        expected_shape = (self._number_of_channels, num_features_per_channel, 1)\n",
    "        features = features.reshape(expected_shape)\n",
    "        return features\n",
    "\n",
    "    def train_model(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self._model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "        self._is_trained = True\n",
    "\n",
    "    def predict_command(self, eeg_data):\n",
    "        if not self._is_trained:\n",
    "            raise Exception(\"Model has not been trained yet.\")\n",
    "        \n",
    "        # Extract features from the EEG data\n",
    "        features = self.extract_features(eeg_data)\n",
    "        \n",
    "        # Ensure the features have the correct shape (1, number_of_channels, number_of_features)\n",
    "        features = features.reshape(1, self._number_of_channels, -1)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self._model.predict(features)\n",
    "        \n",
    "        # Get the predicted label index\n",
    "        predicted_label_index = np.argmax(prediction, axis=1)[0]\n",
    "        \n",
    "        # Convert the numerical prediction to the text label\n",
    "        predicted_command = self._reverse_label_map[predicted_label_index]\n",
    "        \n",
    "        return predicted_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'bias (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/estudiante/Documents/GitHub/bias/bias/bin/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def generate_synthetic_eeg(n_samples, n_channels, fs):\n",
    "    \"\"\"\n",
    "    Generate synthetic raw EEG data for multiple channels. \n",
    "    The output is a dictionary where each channel has 1000 raw samples.\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, n_samples/fs, n_samples, endpoint=False)\n",
    "    data = {}\n",
    "\n",
    "    for ch in range(n_channels):\n",
    "        # Create a raw EEG signal by summing several sine waves to simulate brain activity\n",
    "        signal = (\n",
    "            random.randrange(0, 10) * np.sin(2 * np.pi * random.randrange(8, 13) * t) +  # Simulate alpha wave (8-13 Hz)\n",
    "            random.randrange(0, 10) * np.sin(2 * np.pi * random.randrange(13, 30) * t) +  # Simulate beta wave (13-30 Hz)\n",
    "            random.randrange(0, 10) * np.sin(2 * np.pi * random.randrange(4, 8) * t) +   # Simulate theta wave (4-8 Hz)\n",
    "            random.randrange(0, 10) * np.sin(2 * np.pi * random.randrange(1, 4) * t) +   # Simulate delta wave (0.5-4 Hz)\n",
    "            random.randrange(0, 10) * np.sin(2 * np.pi * random.randrange(0, 50) * t)    # Simulate gamma wave (30-100 Hz)\n",
    "        )\n",
    "\n",
    "        # Add random noise to simulate realistic EEG signals\n",
    "        noise = np.random.normal(0, 0.5, size=t.shape)\n",
    "        signal += noise\n",
    "\n",
    "        # Store the raw signal in the dictionary\n",
    "        data[ch] = signal\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'bias (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/estudiante/Documents/GitHub/bias/bias/bin/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    n = 1000\n",
    "    fs = 500\n",
    "    online = True\n",
    "    number_of_channels = 4\n",
    "    port = '/dev/serial0'\n",
    "    baudrate = 115200\n",
    "    timeout = 1\n",
    "    biasReception = ReceptionBias(port, baudrate, timeout)\n",
    "    biasFilter = FilterBias(n=n, fs=fs, notch=True, bandpass=True, fir=False, iir=False)\n",
    "    biasProcessing = ProcessingBias(n=n, fs=fs)\n",
    "    commands = [\"forward\", \"backward\", \"left\", \"right\", \"stop\", \"rest\"]\n",
    "    biasAI = AIBias(n=n, fs=fs, channels=number_of_channels, commands=commands)\n",
    "    biasAI.collect_and_train(reception_instance=biasReception, filter_instance=biasFilter, processing_instance=biasProcessing, \n",
    "                             samples_per_command=1, real_data=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'bias (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/estudiante/Documents/GitHub/bias/bias/bin/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def predict_command():    \n",
    "    # Generate synthetic data\n",
    "    signals = generate_synthetic_eeg(n_samples=n, n_channels=number_of_channels, fs=fs)\n",
    "    #signals = biasReception.get_real_data(channels=number_of_channels, n=n)\n",
    "    \n",
    "    filtered_data = biasFilter.filter_signals(signals)\n",
    "    # Process data\n",
    "    times, eeg_signals = biasProcessing.process_signals(filtered_data)\n",
    "    predicted_command = biasAI.predict_command(eeg_data=eeg_signals)\n",
    "    print(f\"Predicted Command: {predicted_command}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'bias (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/estudiante/Documents/GitHub/bias/bias/bin/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'bias (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/estudiante/Documents/GitHub/bias/bias/bin/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "predict_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
